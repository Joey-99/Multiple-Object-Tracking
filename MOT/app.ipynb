{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Object Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single object tracking: mainly by finding the most similar area around the ball to complete the tracking\n",
    "### Multi-object tracking: use yolov5 to complete target detection, and do matching by Kalman filters to predict position and Hungarian algorithm to complete tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anaconda3\n",
    "# opencv-python\n",
    "# filterpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Yolov5():\n",
    "    def __init__(self, modelpath, confThreshold=0.3, nmsThreshold=0.5, objThreshold=0.5):\n",
    "        with open('class.names', 'rt') as f:\n",
    "            self.classes = f.read().rstrip('\\n').split('\\n')\n",
    "        self.num_classes = len(self.classes)\n",
    "        if modelpath.endswith('6.onnx'):\n",
    "            self.inpHeight, self.inpWidth = 1280, 1280\n",
    "            anchors = [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542],\n",
    "                       [436, 615, 739, 380, 925, 792]]\n",
    "            self.stride = np.array([8., 16., 32., 64.])\n",
    "        else:\n",
    "            self.inpHeight, self.inpWidth = 640, 640\n",
    "\n",
    "            anchors = [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]\n",
    "            self.stride = np.array([8., 16., 32.])\n",
    "        self.nl = len(anchors)\n",
    "        self.na = len(anchors[0]) // 2\n",
    "        self.grid = [np.zeros(1)] * self.nl\n",
    "        self.anchor_grid = np.asarray(anchors, dtype=np.float32).reshape(self.nl, -1, 2)\n",
    "        self.net = cv2.dnn.readNet(modelpath)\n",
    "        self.confThreshold = confThreshold\n",
    "        self.nmsThreshold = nmsThreshold\n",
    "        self.objThreshold = objThreshold\n",
    "        self._inputNames = ''\n",
    "\n",
    "    def resize_image(self, srcimg, keep_ratio=True, dynamic=False):\n",
    "        top, left, newh, neww = 0, 0, self.inpWidth, self.inpHeight\n",
    "        if keep_ratio and srcimg.shape[0] != srcimg.shape[1]:\n",
    "            hw_scale = srcimg.shape[0] / srcimg.shape[1]\n",
    "            if hw_scale > 1:\n",
    "                newh, neww = self.inpHeight, int(self.inpWidth / hw_scale)\n",
    "                img = cv2.resize(srcimg, (neww, newh), interpolation=cv2.INTER_AREA)\n",
    "                if not dynamic:\n",
    "                    left = int((self.inpWidth - neww) * 0.5)\n",
    "                    img = cv2.copyMakeBorder(img, 0, 0, left, self.inpWidth - neww - left, cv2.BORDER_CONSTANT,\n",
    "                                             value=(114, 114, 114))  # add border\n",
    "            else:\n",
    "                newh, neww = int(self.inpHeight * hw_scale), self.inpWidth\n",
    "                img = cv2.resize(srcimg, (neww, newh), interpolation=cv2.INTER_AREA)\n",
    "                if not dynamic:\n",
    "                    top = int((self.inpHeight - newh) * 0.5)\n",
    "                    img = cv2.copyMakeBorder(img, top, self.inpHeight - newh - top, 0, 0, cv2.BORDER_CONSTANT,\n",
    "                                             value=(114, 114, 114))\n",
    "        else:\n",
    "            img = cv2.resize(srcimg, (self.inpWidth, self.inpHeight), interpolation=cv2.INTER_AREA)\n",
    "        return img, newh, neww, top, left\n",
    "\n",
    "    def _make_grid(self, nx=20, ny=20):\n",
    "        xv, yv = np.meshgrid(np.arange(ny), np.arange(nx))\n",
    "        return np.stack((xv, yv), 2).reshape((-1, 2)).astype(np.float32)\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        return img\n",
    "\n",
    "    def postprocess(self, frame, outs, padsize=None):\n",
    "        frameHeight = frame.shape[0]\n",
    "        frameWidth = frame.shape[1]\n",
    "        newh, neww, padh, padw = padsize\n",
    "        ratioh, ratiow = frameHeight / newh, frameWidth / neww\n",
    "        # Scan through all the bounding boxes output from the network and keep only the\n",
    "        # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        classIds = []\n",
    "        for detection in outs:\n",
    "            if detection[4] > self.objThreshold:\n",
    "                scores = detection[5:]\n",
    "                classId = np.argmax(scores)\n",
    "                confidence = scores[classId] * detection[4]\n",
    "                if confidence > self.confThreshold:\n",
    "                    center_x = int((detection[0] - padw) * ratiow)\n",
    "                    center_y = int((detection[1] - padh) * ratioh)\n",
    "                    width = int(detection[2] * ratiow)\n",
    "                    height = int(detection[3] * ratioh)\n",
    "                    left = int(center_x - width * 0.5)\n",
    "                    top = int(center_y - height * 0.5)\n",
    "\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([left, top, width, height])\n",
    "                    classIds.append(classId)\n",
    "        if len(boxes)==0:\n",
    "            return frame,[]\n",
    "        # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "        # lower confidences.\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, self.confThreshold, self.nmsThreshold).flatten()\n",
    "        out=[]\n",
    "        for i in indices:\n",
    "            box = boxes[i]\n",
    "            left = box[0]\n",
    "            top = box[1]\n",
    "            width = box[2]\n",
    "            height = box[3]\n",
    "            \n",
    "            out.append((classIds[i],boxes[i]))\n",
    "            # frame = self.drawPred(frame, classIds[i], confidences[i], left, top, left + width, top + height)\n",
    "        return frame,out\n",
    "\n",
    "    def drawPred(self, frame, classId, conf, left, top, right, bottom):\n",
    "        # Draw a bounding box.\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), thickness=4)\n",
    "\n",
    "        label = '%.2f' % conf\n",
    "        label = '%s:%s' % (self.classes[classId], label)\n",
    "\n",
    "        # Display the label at the top of the bounding box\n",
    "        labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        top = max(top, labelSize[1])\n",
    "        # cv.rectangle(frame, (left, top - round(1.5 * labelSize[1])), (left + round(1.5 * labelSize[0]), top + baseLine), (255,255,255), cv.FILLED)\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=2)\n",
    "        return frame\n",
    "\n",
    "    def detect(self, srcimg):\n",
    "        drawImg=srcimg.copy()\n",
    "        \n",
    "        img, newh, neww, padh, padw = self.resize_image(srcimg)\n",
    "        blob = cv2.dnn.blobFromImage(img, scalefactor=1 / 255.0, swapRB=True)\n",
    "        # blob = cv2.dnn.blobFromImage(self.preprocess(img))\n",
    "        # Sets the input to the network\n",
    "        self.net.setInput(blob, self._inputNames)\n",
    "\n",
    "        # Runs the forward pass to get output of the output layers\n",
    "        outs = self.net.forward(self.net.getUnconnectedOutLayersNames())[0].squeeze(axis=0)\n",
    "\n",
    "        # inference output\n",
    "        row_ind = 0\n",
    "        for i in range(self.nl):\n",
    "            h, w = int(self.inpHeight / self.stride[i]), int(self.inpWidth / self.stride[i])\n",
    "            length = int(self.na * h * w)\n",
    "            if self.grid[i].shape[2:4] != (h, w):\n",
    "                self.grid[i] = self._make_grid(w, h)\n",
    "\n",
    "            outs[row_ind:row_ind + length, 0:2] = (outs[row_ind:row_ind + length, 0:2] * 2. - 0.5 + np.tile(\n",
    "                self.grid[i], (self.na, 1))) * int(self.stride[i])\n",
    "            outs[row_ind:row_ind + length, 2:4] = (outs[row_ind:row_ind + length, 2:4] * 2) ** 2 * np.repeat(\n",
    "                self.anchor_grid[i], h * w, axis=0)\n",
    "            row_ind += length\n",
    "        \n",
    "        \n",
    "        drawImg,out = self.postprocess(drawImg, outs, padsize=(newh, neww, padh, padw))\n",
    "        return drawImg,out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# from numba import jit\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# @jit\n",
    "def iou(bb_test, bb_gt):\n",
    "    \"\"\"\n",
    "    calculate IOU between 2 boxes\n",
    "    :param bb_test: box1 = [x1y1x2y2]\n",
    "    :param bb_gt: box2 = [x1y1x2y2]\n",
    "    :return: Intersection-over-Union, IoU\n",
    "    \"\"\"\n",
    "    xx1 = np.maximum(bb_test[0], bb_gt[0])\n",
    "    yy1 = np.maximum(bb_test[1], bb_gt[1])\n",
    "    xx2 = np.minimum(bb_test[2], bb_gt[2])\n",
    "    yy2 = np.minimum(bb_test[3], bb_gt[3])\n",
    "    w = np.maximum(0., xx2 - xx1)\n",
    "    h = np.maximum(0., yy2 - yy1)\n",
    "    wh = w * h\n",
    "    o = wh / ((bb_test[2] - bb_test[0]) * (bb_test[3] - bb_test[1]) + (bb_gt[2] - bb_gt[0]) * (\n",
    "            bb_gt[3] - bb_gt[1]) - wh)\n",
    "    return o\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "    \"\"\"\n",
    "    The detection frame of the form [x1,y1,x2,y2] is converted into the state representation of the filter in the form [x,y,s,r]. \n",
    "        where x, y are the center coordinates of the box, s is the area, scale, and r is the aspect ratio\n",
    "    :param bbox: [x1,y1,x2,y2] are the top-left and bottom-right coordinates, respectively\n",
    "    :return: [ x, y, s, r ] 4 rows and 1 column, \n",
    "        where x,y are the coordinates of the box center position, s is the area, r is the aspect ratio w/h\n",
    "    \"\"\"\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "    x = bbox[0] + w / 2.\n",
    "    y = bbox[1] + h / 2.\n",
    "    s = w * h\n",
    "    r = w / float(h)\n",
    "    return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "def convert_x_to_bbox(x, score=None):\n",
    "    \"\"\"\n",
    "    Convert the target box representation of [cx, cy, s, r] to the form of [x_min, y_min, x_max, y_max]\n",
    "    :param x:[ x, y, s, r ],where x,y are the coordinates of the box center position, s is the area, r\n",
    "    :param score: confidence level\n",
    "    :return:[x1,y1,x2,y2],Top-left and bottom-right coordinates\n",
    "    \"\"\"\n",
    "    w = np.sqrt(x[2] * x[3])\n",
    "    h = x[2] / w\n",
    "    if score is None:\n",
    "        return np.array([x[0] - w / 2., x[1] - h / 2., x[0] + w / 2., x[1] + h / 2.]).reshape((1, 4))\n",
    "    else:\n",
    "        return np.array([x[0] - w / 2., x[1] - h / 2., x[0] + w / 2., x[1] + h / 2., score]).reshape((1, 5))\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "    count = 0\n",
    "\n",
    "    def __init__(self, bbox):\n",
    "        \"\"\"\n",
    "        Initialize bounding boxes and trackers\n",
    "        :param bbox:\n",
    "        \"\"\"\n",
    "        # constant velocity definition\n",
    "        # use KalmanFilter inside，7 state variables and 4 observation inputs\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        self.kf.F = np.array(\n",
    "            [[1, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1]])\n",
    "        self.kf.H = np.array(\n",
    "            [[1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0]])\n",
    "        self.kf.R[2:, 2:] *= 10.\n",
    "        self.kf.P[4:, 4:] *= 1000.  # give high uncertainty to the unobservable initial velocities\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q[-1, -1] *= 0.01\n",
    "        self.kf.Q[4:, 4:] *= 0.01\n",
    "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "        self.time_since_update = 0  # record the number of predictions from the last update to the current frame, and clear 0 after each update (in the update function)\n",
    "        self.id = KalmanBoxTracker.count\n",
    "        KalmanBoxTracker.count += 1\n",
    "        self.history = []\n",
    "        self.hits = 0\n",
    "        self.hit_streak = 0  # record number of tracked, directly clear to 0 once a frame is missed(in predict function)\n",
    "        self.age = 0\n",
    "\n",
    "    def update(self, bbox):\n",
    "        \"\"\"\n",
    "        update state vector with the observed target box\n",
    "        filterpy.kalman.KalmanFilter.update will modify internal state, estimate self.kf.x based on observations\n",
    "        reset self.time_since_update, clear self.history。\n",
    "        :param bbox: target box\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.history = []\n",
    "        self.hits += 1\n",
    "        self.hit_streak += 1\n",
    "        self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Advance state vector and return predicted bounding box estimate\n",
    "        append the prediction to self.history\n",
    "        since get_state accesses self.kf.x directly, self.history isn't used\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if (self.kf.x[6] + self.kf.x[2]) <= 0:\n",
    "            self.kf.x[6] *= 0.0\n",
    "        self.kf.predict()\n",
    "        # predition times\n",
    "        self.age += 1\n",
    "        # if there's no updates during tracking, put hit_streak = 0\n",
    "        if self.time_since_update > 0:\n",
    "            self.hit_streak = 0\n",
    "        self.time_since_update += 1\n",
    "        # append prediction results to history\n",
    "        self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "        return self.history[-1]\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        return current bounding box estimation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return convert_x_to_bbox(self.kf.x)\n",
    "\n",
    "def associate_detections_to_trackers(detections, trackers, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Match the detection box bbox with the tracking box of the Kalman filter by association\n",
    "    :param detections:detection box\n",
    "    :param trackers:tracking box, or tracking target\n",
    "    :param iou_threshold:IOU threshold\n",
    "    :return:matrix for tracking successful targets: matchs\n",
    "            Matrix of added targets: unmatched_detections\n",
    "            Tracking failed(leave the screen) target matrix: unmatched_trackers\n",
    "    \"\"\"\n",
    "    # if the number of tracking targets = 0, construct results directly\n",
    "    if (len(trackers) == 0) or (len(detections) == 0):\n",
    "        return np.empty((0, 2), dtype=int), np.arange(len(detections)), np.empty((0, 5), dtype=int)\n",
    "\n",
    "    # iou doesn't support array calculation. Calculate IOU in pairs one by one and call linear_assignment for matching\n",
    "    iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n",
    "    # traverse bbox sets of target detection, each identification of detection box is d\n",
    "    for d, det in enumerate(detections):\n",
    "        # Traverse tracking box (Kalman filter prediction) bbox set，each tracking box is identified by t\n",
    "        for t, trk in enumerate(trackers):\n",
    "            iou_matrix[d, t] = iou(det, trk)\n",
    "    # store tracking and detection boxes as [[d,t]...] 2-d arrays in match_indices by Hungarian algorithm\n",
    "    result = linear_sum_assignment(-iou_matrix)\n",
    "    matched_indices = np.array(list(zip(*result)))\n",
    "\n",
    "    # Record unmatched detection boxes and tracking boxes\n",
    "    # put unmatched detection boxed into unmatched_detections，represent there's new target enter the screen, need to add tracker\n",
    "    unmatched_detections = []\n",
    "    for d, det in enumerate(detections):\n",
    "        if d not in matched_indices[:, 0]:\n",
    "            unmatched_detections.append(d)\n",
    "    # put unmatched tracking boxed into unmatched_trackers, represent target leaves the screen and the corresponding tracker should be deleted\n",
    "    unmatched_trackers = []\n",
    "    for t, trk in enumerate(trackers):\n",
    "        if t not in matched_indices[:, 1]:\n",
    "            unmatched_trackers.append(t)\n",
    "    # put tracking boxes matched successfully into matches\n",
    "    matches = []\n",
    "    for m in matched_indices:\n",
    "        # filter mataches with low IOU, put them into unmatched_detections and unmatched_trackers\n",
    "        if iou_matrix[m[0], m[1]] < iou_threshold:\n",
    "            unmatched_detections.append(m[0])\n",
    "            unmatched_trackers.append(m[1])\n",
    "        # put the ones meet conditions into matches in form of [[d,t]...]\n",
    "        else:\n",
    "            matches.append(m.reshape(1, 2))\n",
    "    # Initialize matches, return in the format of np.array\n",
    "    if len(matches) == 0:\n",
    "        matches = np.empty((0, 2), dtype=int)\n",
    "    else:\n",
    "        matches = np.concatenate(matches, axis=0)\n",
    "\n",
    "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "\n",
    "class Sort(object):\n",
    "    def __init__(self, max_age=1, min_hits=3):\n",
    "        \"\"\"\n",
    "        Initialization: set the key parameters of the SORT algorithm       \n",
    "        \"\"\"\n",
    "        # max of detections: number of object frames that didn't detected, will be deleted when it exceed\n",
    "        self.max_age = max_age\n",
    "        # min of target hits, won't return if less than this\n",
    "        self.min_hits = min_hits  \n",
    "        # kalman filter\n",
    "        self.trackers = []  \n",
    "        # frame count\n",
    "        self.frame_count = 0\n",
    "    \n",
    "    def update(self, dets):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        dets  [[x1,y1 ,x2,y2]]\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        # Predict trajectory positions one by one in the current frame and record the tracker index for state anomalies\n",
    "        # create 2-d arrays according to the numbers of current all kalman trackers（Number of targets tracked in the previous frame）\n",
    "        # ：row is the identification index of the Kalman filter, column is the position and ID of the tracking frame\n",
    "        trks = np.zeros((len(self.trackers), 5))  # Store prediction of trackers\n",
    "        to_del = []   # store target boxes to be deleted\n",
    "        ret = []    # store tracking boxes to be returned\n",
    "        # Loop traverse Kalman tracker list\n",
    "        for t, trk in enumerate(trks):\n",
    "            # use Kalman tracker t to generate tracking frame of corresponding target\n",
    "            pos = self.trackers[t].predict()[0]\n",
    "            # after traverse，trk stores predicted tracking box of the target tracked in previous frame\n",
    "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "            # if contains null in tracking box, add this tracking box to the list to be delete\n",
    "            if np.any(np.isnan(pos)):\n",
    "                to_del.append(t)\n",
    "        # numpy.ma.masked_invalid shield arrays with invalid values（NaN or inf）\n",
    "        # numpy.ma.compress_rows compress entire line contains 2-d array with mask value，will remove entire line with mask value\n",
    "        # trks stores object tracked in previous frame and the predicted tracking frame in current frame\n",
    "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "        # Reverse delete abnormal trackers to prevent index corruption\n",
    "        for t in reversed(to_del):\n",
    "            self.trackers.pop(t)\n",
    "        # associate target detection box and tracking box Kalman filter predicted with targets tracked successfully, added and leaved\n",
    "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets, trks)\n",
    "\n",
    "        # Update the successfully tracked target frame to the corresponding Kalman filter\n",
    "        for t, trk in enumerate(self.trackers):\n",
    "            if t not in unmatched_trks:\n",
    "                d = matched[np.where(matched[:, 1] == t)[0], 0]\n",
    "                # update state vector using observed bounding box\n",
    "                trk.update(dets[d, :][0])\n",
    "\n",
    "        # create new kalman filter object for the added target to track \n",
    "        for i in unmatched_dets:\n",
    "            trk = KalmanBoxTracker(dets[i, :])\n",
    "            self.trackers.append(trk)\n",
    "\n",
    "        # Back-to-Forward Traverse，only return results appear in current frame and hit period more than self.min_hits（unless tracking just begins）；if unhit time more than self.max_age, delete the tracker.\n",
    "        # hit_streak ignore some initial frames of the target\n",
    "        i = len(self.trackers)\n",
    "        for trk in reversed(self.trackers):\n",
    "            # return the estimated value of the current bounding box\n",
    "            d = trk.get_state()[0]\n",
    "            # put box and id of targets successfully tracked into ret list\n",
    "            if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "                ret.append(np.concatenate((d, [trk.id + 1])).reshape(1, -1))  # +1 as MOT benchmark requires positive\n",
    "            i -= 1\n",
    "            # Targets that fail to track or leave the screen are removed from the Kalman tracker\n",
    "            if trk.time_since_update > self.max_age:\n",
    "                self.trackers.pop(i)\n",
    "        # Return box and id of all targets in the current screen, as a two-dimensional matrix\n",
    "        if len(ret) > 0:\n",
    "            return np.concatenate(ret)\n",
    "        return np.empty((0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yolo = Yolov5('yolov5n.onnx')\n",
    "# create tracker  max_age  number of shades\n",
    "tracker = Sort(max_age=10)\n",
    "# generate different colors\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(200, 3), dtype='uint8')\n",
    "# store center point\n",
    "pts = [deque(maxlen=30) for _ in range(9999)]\n",
    "# frame rate\n",
    "fps = 0\n",
    "cap = cv2.VideoCapture(\"./multiObject.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame by frame detection and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # read the video\n",
    "    (ret, frame) = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t1 = time.time()\n",
    "    # object detection\n",
    "    srcimg,outs = yolo.detect(frame)\n",
    "    if len(outs)==0:\n",
    "        continue\n",
    "    dets=[x for id,x in outs ]\n",
    "    ddets=[]\n",
    "    for box in dets:\n",
    "        x,y,w,h=box\n",
    "        ddets.append([x,y,w+x,h+y])\n",
    "    dets=np.array(ddets)\n",
    "    if len(dets) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        # multiple object tracking\n",
    "        # dets  [[x1,y1 ,x2,y2]]\n",
    "        tracks = tracker.update(dets)\n",
    "    # process and display tracking results\n",
    "    num = 0\n",
    "    for track in tracks:\n",
    "        bbox = track[:4] # Tracking box coordinates\n",
    "        indexID = int(track[4]) # Tracking ID\n",
    "        # Randomly assigned colors\n",
    "        color = [int(c) for c in COLORS[indexID % len(COLORS)]]\n",
    "        # The parameters in order are: photo / (upper left corner, lower right corner) / color / line width\n",
    "        cv2.rectangle(frame, (int(bbox[0]),int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n",
    "        # The parameters in order are: photo / added text / top left corner coordinates / font / font size / color / font thickness\n",
    "        cv2.putText(frame, str(indexID), (int(bbox[0]), int(bbox[1] - 10)), 0, 5e-1, color, 1)\n",
    "        num += 1\n",
    "        # center of detection frame(x,y)\n",
    "        center = (int(((bbox[0]) + (bbox[2])) / 2), int(((bbox[1]) + (bbox[3])) / 2))\n",
    "        pts[indexID].append(center)\n",
    "        cv2.circle(frame, (center), 1, color, 2)\n",
    "        # Display motion trajectory\n",
    "        for j in range(1, len(pts[indexID])):\n",
    "            if pts[indexID][j - 1] is None or pts[indexID][j] is None:\n",
    "                continue\n",
    "            cv2.line(frame, (pts[indexID][j -1]), (pts[indexID][j]), color, 2)\n",
    "   \n",
    "    #show results\n",
    "\n",
    "\n",
    "    # cv2.putText(frame, \"FPS: %f\" %(fps), (int(20),int(20)), 0, 5e-1, (0,255,0), 2)\n",
    "    cv2.namedWindow(\"track\", 0)\n",
    "    cv2.resizeWindow('track', 1280, 720)\n",
    "    # # Calculate frame rate\n",
    "    # fps = (fps + (1. / (time.time() - t1))) / 2\n",
    "\n",
    "    cv2.imshow('track', frame)\n",
    "    # Q to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
